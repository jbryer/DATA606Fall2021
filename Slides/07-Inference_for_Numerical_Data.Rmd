---
title: "Inference for Numerical Data"
subtitle: "DATA 606 - Statistics & Probability for Data Analytics"
author: Jason Bryer, Ph.D. and Angela Lui, Ph.D.
date: "October 20, 2021"
output:
  xaringan::moon_reader:
    css: ["assets/mtheme_max.css", "assets/fonts_mtheme_max.css"]
    self_contained: true
    lib_dir: libs
    nature:
      highlightStyle: solarized-light
      highlightLanguage: R
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
      navigation:
        scroll: false
    includes:
      in_header: [assets/header.html]
      after_body: [assets/insert-logo.html]
params:
  github_link: "DATA606Fall2021"
  one_minute_paper: "https://forms.gle/ENFqTnDB5fJDw3kx9"
  one_minute_paper_results: "https://docs.google.com/spreadsheets/d/1mhAT8YeBQek1r7tqz0j96-fYhU3arZwpVw623RjlaBs/edit?resourcekey#gid=1608172812"
editor_options: 
  chunk_output_type: console
---

```{r setup, include = FALSE}
# remotes::install_github("gadenbuie/countdown")
# remotes::install_github("mitchelloharawild/icon")
# icon::download_fontawesome()
library(knitr)
library(tidyverse)
library(countdown)
library(openintro)
library(DATA606)
library(reshape2)
library(latex2exp)
library(psych)

set.seed(2112)

knitr::opts_chunk$set(warning = FALSE, message = FALSE, error = FALSE, 
					  fig.width = 12, fig.height=6.5, fig.align = 'center',
					  digits = 3) 
options(width = 120)
# The following is to fix a DT::datatable issue with Xaringan
# https://github.com/yihui/xaringan/issues/293
options(htmltools.dir.version = FALSE, htmltools.preserve.raw = FALSE)

# This style was adapted from Max Kuhn: https://github.com/rstudio-conf-2020/applied-ml
# And Rstudio::conf 2020: https://github.com/rstudio-conf-2020/slide-templates/tree/master/xaringan
# This slide deck shows a lot of the features of Xaringan: https://www.kirenz.com/slides/xaringan-demo-slides.html

# To use, add this to the slide title:   `r I(hexes(c("DATA606")))`
# It will use images in the images/hex_stickers directory (i.e. the filename is the paramter)
hexes <- function(x) {
  x <- rev(sort(x))
  markup <- function(pkg) glue::glue('<img src="images/hex/{pkg}.png" class="title-hex">')
  res <- purrr::map_chr(x, markup)
  paste0(res, collapse = "")
}

# Cartoons from https://github.com/allisonhorst/stats-illustrations
# dplyr based upon https://allisonhorst.shinyapps.io/dplyr-learnr/#section-welcome

PlotDist <- function(alpha, from = -5, to = 5, n = 1000, filename = NULL,
    alternative = c("two.tailed", "greater", "lesser"), 
    distribution = c("normal", "t", "F", "chisq", "binomial"), 
    colour = "black", fill = "skyblue2",
    ...)
{
    alternative <- match.arg(alternative)
    alt.alpha <- switch(alternative, two.tailed = alpha/2, greater = alpha,
        lesser = alpha)
    MyDen <- switch(distribution, normal = dnorm, t = dt, F = df,
        chisq = dchisq, binomial = dbinom)
    MyDist <- switch(distribution, normal = qnorm, t = qt, F = qf,
        chisq = qchisq, binomial = qbinom)
    crit.lower <- MyDist(p = alt.alpha, lower.tail = TRUE, ...)
    crit.upper <- MyDist(p = alt.alpha, lower.tail = FALSE, ...)
    cord.x1 <- c(from, seq(from = from, to = crit.lower, length.out = 100),
        crit.lower)
    cord.y1 <- c(0, MyDen(x = seq(from = from, to = crit.lower,
        length.out = 100), ...), 0)
    cord.x2 <- c(crit.upper, seq(from = crit.upper, to = to,
        length.out = 100), to)
    cord.y2 <- c(0, MyDen(x = seq(from = crit.upper, to = to,
        length.out = 100), ...), 0)
    if (!is.null(filename)) pdf(file = filename)
    curve(MyDen(x, ...), from = from, to = to, n = n, col = colour,
        lty = 1, lwd = 2, ylab = "Density", xlab = "Values")
    if (!identical(alternative, "greater")) {
        polygon(x = cord.x1, y = cord.y1, col = fill)
    }
    if (!identical(alternative, "lesser")) {
        polygon(x = cord.x2, y = cord.y2, col = fill)
    }
    if (!is.null(filename)) dev.off()
}
```

# One Minute Paper Results

```{r, echo=FALSE}
library(googlesheets4)
omp <- read_sheet(params$one_minute_paper_results)
omp <- omp %>% dplyr::filter(Topic == 'Inference for Categorical Data (Chapter 6)')
source('word_cloud.R')
```

.pull-left[
**What was the most important thing you learned during this class?**
```{r, echo=FALSE, fig.height=9}
ompWordCloud(omp$`What was the most important thing you learned during this class?`)
```
]
.pull-right[
**What important question remains unanswered for you?**
```{r, echo=FALSE, fig.height=9}
ompWordCloud(omp$`What important question remains unanswered for you?`)
```
]

---
class: font140
# Homework Presentations

* 6.23	Coffy Andrews-Guo
	
* 6.47	Santiago Torres

---
# Data Project Proposal

Due October 31<sup>st</sup>ish Select a dataset that interests you. For the proposal, you need to answer the questions below.

.font80[
* Research question
* What type of statistical test do you plan to do (e.g. t-test, ANOVA, regression, logistic regression, chi-squared, etc.)
* What are the cases, and how many are there?
* Describe the method of data collection.
* What type of study is this (observational/experiment)?
* Data Source: If you collected the data, state self-collected. If not, provide a citation/link.
* Response: What is the response variable, and what type is it (numerical/categorical)?
* Explanatory: What is the explanatory variable(s), and what type is it (numerical/categorical)?
* Relevant summary statistics
]

More information including template and suggested datasets located here: https://fall2021.data606.net/assignments/project/




---
# High School & Beyond Survey  

`r nrow(hsb2)` randomly selected students completed the reading and writing test of the High School and Beyond survey. The results appear to the right. Does there appear to be a difference?

```{r, fig.width=5, fig.height=3.7, eval=TRUE}
data(hsb2) # in openintro package
hsb2.melt <- melt(hsb2[,c('id','read', 'write')], id='id')
ggplot(hsb2.melt, aes(x=variable, y=value)) + 	geom_boxplot() + 
	geom_point(alpha=0.2, color='blue') + xlab('Test') + ylab('Score')
```


---
# High School & Beyond Survey  

```{r}
head(hsb2)
```

Are the reading and writing scores of each student independent of each other?


---
# Analyzing Paired Data  

* When two sets of observations are not independent, they are said to be paired.
* To analyze these type of data, we often look at the difference.

```{r, fig.width=6, fig.height=4}
hsb2$diff <- hsb2$read - hsb2$write
head(hsb2$diff)
```

```{r, fig.width=6, fig.height=3}
hist(hsb2$diff)
```


---
# Setting the Hypothesis

What are the hypothesis for testing if there is a difference between the average reading and writing scores?

$H_0$: There is no difference between the average reading and writing scores.

$$\mu_{diff} = 0$$

$H_A$: There is a difference between the average reading and writing score.

$$\mu_{diff} \ne 0$$

---
class: font120
# Nothing new here...

* The analysis is no different that what we have done before.
* We have data from one sample: differences.
* We are testing to see if the average difference is different that 0.

---
# Calculating the test-statistic and the p-value 

The observed average difference between the two scores is `r mean(hsb2$diff)` points and the standard deviation of the difference is `r sd(hsb2$diff)` points. Do these data provide confincing evidence of a difference between the average scores ont eh two exams (use $\alpha = 0.05$)?

```{r, fig.height = 6, echo=FALSE}
meanDiff <- mean(hsb2$diff)
sdDiff <- sd(hsb2$diff)
normal_plot(mean=0, cv = c(-1 * abs(meanDiff), abs(meanDiff)), tails = 'two.sided')
```

---
# Calculating the test-statistic and the p-value 

$$Z = \frac{-0.545 - 0}{ \frac{8.887}{\sqrt{200}} } = \frac{-0.545}{0.628} = -0.87$$
$$p-value = 0.1949 \times 2 = 0.3898$$

Since p-value > 0.05, we fail to reject the null hypothesis. That is, the data do not provide evidence that there is a statistically significant difference between the average reading and writing scores.

```{r}
2 * pnorm(mean(hsb2$diff), mean=0, sd=sd(hsb2$diff)/sqrt(nrow(hsb2)))
```

---
# Evaluating the null hypothesis

## Interpretation of the p-value

The probability of obtaining a random sample of 200 students where the average difference between the reading and writing scores is at least 0.545 (in either direction), if in fact the true average difference between the score is 0, is 38%.

--
## Calculating 95% Confidence Interval

$$-0.545\pm 1.96\frac { 8.887 }{ \sqrt { 200 }  } =-0.545\pm 1.96\times 0.628=(-1.775, 0.685)$$

Note that the confidence interval spans zero!

---
# SAT Scores by Sex

```{r}
data(sat)
head(sat)
```

```{r, echo=FALSE, results='hide', warning=FALSE}
sat$Math.SAT <- as.integer(sat$Math.SAT)
sat <- sat[complete.cases(sat),]
```

Is there a difference in math scores between males and females?

---
# SAT Scores by Sex 

.pull-left[
```{r}
tab <- describeBy(sat$Math.SAT, 
		   group=sat$Sex, 
		   mat=TRUE, skew=FALSE)
tab[,c(2,4:7)]
```
]

.pull-right[
```{r, fig.height=7}
ggplot(sat, aes(x=Sex, y=Math.SAT)) + 
	geom_boxplot() +
	geom_point(data = tab, aes(x=group1, y=mean), 
			   color='blue', size=4)
```
]

---
# Distributions  


```{r}
ggplot(sat, aes(x=Math.SAT, color = Sex)) + geom_density()
```

---
class: font120
# 95% Confidence Interval

We wish to calculate a 95% confidence interval for the average difference between SAT scores for males and females.

Assumptions:

1. Independence within groups.

2. Independence between groups.

3. Sample size/skew

---
# Confidence Interval for Difference Between Two Means

* All confidence intervals have the same form: point estimate Â± ME
* And all ME = critical value * SE of point estimate
* In this case the point estimate is $\bar{x}_1 - \bar{x}_2$
Since the sample sizes are large enough, the critical value is z*
So the only new concept is the standard error of the difference between two means...

Standard error of the difference between two sample means

$$SE_{ (\bar { x } _{ 1 }-\bar { x } _{ 2 }) }=\sqrt { \frac { { s }_{ 1 }^{ 2 } }{ { n }_{ 1 } } +\frac { { s }_{ 2 }^{ 2 } }{ { n }_{ 2 } }  }$$
--

Confidence Interval for Difference in SAT Scores

$$SE_{ (\bar { x } _{ 1 }-\bar { x } _{ 2 }) }=\sqrt { \frac { { s }_{ M }^{ 2 } }{ { n }_{ M } } + \frac { { s }_{ F }^{ 2 } }{ { n }_{ F } }  } = \sqrt { \frac { 90.4 }{ 80 } +\frac { 103.7 }{ 82 }  } =1.55$$

---
# Student's *t*-Distribution 

What if you want to compare the quality of one batch of Guinness beer to the next?

--

.pull-left[
* Sample sizes necessarily need to be small.
* The CLT states that the sampling distribution approximates normal as n -> Infinity
* Need an alternative to the normal distribution.
* The *t* distribution was developed by William Gosset (under the pseudonym *student*) to estimate means when the sample size is small.

Confidence interval is estimated using

$$\overline { x } \pm { t }_{ df }^{ * }SE$$

Where *df* is the degrees of freedom (*df* = *n* -1)
]

.pull-right[.center[
![](images/William_Sealy_Gosset.jpg)
]]

---
# *t*-Distributions 

```{r, echo=FALSE}
x <- seq(-4, 4, length=100)
hx <- dnorm(x)

degf <- c(1, 3, 8, 30)
colors <- c("red", "blue", "darkgreen", "gold", "black")
labels <- c("df=1", "df=3", "df=8", "df=30", "normal")

plot(x, hx, type="l", lty=2, xlab="x value",
  ylab="Density", main="Comparison of t Distributions")

for (i in 1:4){
  lines(x, dt(x,degf[i]), lwd=2, col=colors[i])
}

legend("topright", inset=.05, title="Distributions", labels, lwd=2, lty=c(1, 1, 1, 1, 2), col=colors)
```

---
# *t*-test in R 

The `pt` and `qt` will give you the *p*-value and critical value from the *t*-distribution, respectively.

.pull-left[

Critical value for p = 0.05, degrees of freedom = 10

```{r}
qt(0.025, df = 10)
```

p-value for a critical value of 2, degrees of freedom = 10

```{r}
pt(2, df=10)
```

]
.pull-right[

The `t.test` function will calculate a null hyphothesis test using the *t*-distribution.

```{r}
t.test(Math.SAT ~ Sex, data = sat)
```


```{r, echo=FALSE, results='hide', message=FALSE, warning=FALSE}
require(ggplot2)
require(gdata)
require(psych)
require(granova)
require(granovaGG)
require(lattice)
data(singer)
data(rat)
hand <- read.csv('../course_data/Hand_washing.csv')
```
]


---
# Analysis of Variance (ANOVA)

The goal of ANOVA is to test whether there is a discernible difference between the means of several groups.

--
### Hand Washing Example

Is there a difference between washing hands with:  water only, regular soap, antibacterial soap (ABS), and antibacterial spray (AS)?

* Each tested with 8 replications
* Treatments randomly assigned

For ANOVA:

* The means all differ.
* Is this just natural variability?
* Null hypothesis:  All the means are the same.
* Alternative hypothesis:  The means are not all the same.


---
# Hand Washing Comparison 


```{r hand-boxplot, fig.height=6, tidy=FALSE}
ggplot(hand, aes(x=Method, y=Bacterial.Counts)) + geom_boxplot() + 
	stat_summary(fun = mean, color = 'blue', size = 1.5)
```

---
class: font110
# Hand Washing Comparison (cont.) 

```{r, tidy=FALSE}
desc <- describeBy(hand$Bacterial.Counts, hand$Method, mat=TRUE, skew = FALSE)
desc$Var <- desc$sd^2
print(desc, row.names=FALSE)

mean(desc$Var)

var(hand$Bacterial.Counts)
```


---
# Washing type all the same?

$H_0: \mu_1 = \mu_2 = \mu_3 = \mu_4$

Variance components we need to evaluate the null hypothesis:

* Between Sum of Squares: $SS_{between} = \sum^{}_{k} n_{k}(\bar{x}_{k} -\bar{x} )^{2}$

* Within Sum of Squares: $SS_{within} = \sum^{}_{k} \sum^{}_{i} (\bar{x}_{ik} -\bar{x}_{k} )^{2}$

* Between degrees of freedom: $df_{between} =  k - 1$ (k = number of groups)

* Within degrees of freedom: $df_{within} =  k(n - 1)$

* Mean square between (aka treatment): $MS_{T} = \frac{SS_{between}}{df_{between}}$

* Mean square within (aka error): $MS_{E} = \frac{SS_{within}}{df_{within}}$


```{r, eval=FALSE, echo=FALSE}
( ss_between <- sum(desc$n * (desc$mean - mean(hand$Bacterial.Counts))^2) )
( ss_within <- sum((tmp$Bacterial.Counts - tmp$mean)^2) )
( ss_total <- sum((hand$Bacterial.Counts - mean(hand$Bacterial.Counts))^2) )
tmp <- merge(hand, desc[,c('group1','mean')], by.x = 'Method', by.y = 'group1')
ss_between + ss_within == ss_total # Verify everything adds up
var(hand$Bacterial.Counts) / 4
```


---
# Comparing $MS_T$ (between) and $MS_E$ (within)

.pull-left[
Assume each washing method has the same variance.

Then we can pool them all together to get the pooled variance ${ s }_{ p }^{ 2 }$

Since the sample sizes are all equal, we can average the four variances: ${ s }_{ p }^{ 2 } = `r prettyNum(mean(desc$Var), digits = 6)`$

```{r}
mean(desc$Var)
```
]

--

.pull-right[
$MS_T$

* Estimates ${ s }_{ p }^{ 2 }$ if $H_0$ is true
* Should be larger than ${ s }_{ p }^{ 2 }$ if $H_0$ is false

$MS_E$

* Estimates ${ s }_{ p }^{ 2 }$ whether $H_0$ is true or not
* If $H_0$ is true, both close to ${ s }_{ p }^{ 2 }$, so $MS_T$ is close to $MS_E$

Comparing

* If $H_0$ is true, $\frac{MS_T}{MS_E}$ should be close to 1
* If $H_0$ is false, $\frac{MS_T}{MS_E}$ tends to be > 1
]

---
class: font120
# The F-Distribution 

* How do we tell whether $\frac{MS_T}{MS_E}$ is larger enough to not be due just to random chance?

* $\frac{MS_T}{MS_E}$ follows the F-Distribution
	* Numerator df:  k - 1 (k = number of groups)
	* Denominator df:  k(n - 1)  
	* n = # observations in each group
	
* $F = \frac{MS_T}{MS_E}$ is called the F-Statistic.

A Shiny App by Dr. Dudek to explore the F-Distribution: <a href='https://shiny.rit.albany.edu/stat/fdist/' window='_new'>https://shiny.rit.albany.edu/stat/fdist/</a>

---
# The F-Distribution (cont.) 

```{r fdistribution, fig.width=10, fig.height=6, tidy=FALSE}
df.numerator <- 4 - 1
df.denominator <- 4 * (8 - 1)
F_plot(df.numerator, df.denominator, cv = qf(0.95, df.numerator, df.denominator))
```


---
class: font120
# ANOVA Table


| Source                  | Sum of Squares                                              | *df*  | MS                                   | F                                   | p                              |
| ------------------------|:-----------------------------------------------------------:|:-----:|:------------------------------------:|:-----------------------------------:|--------------------------------|
| Between Group (Treatment) | $\sum^{}_{k} n_{k}(\bar{x}_{k} -\bar{x} )^{2}$              | k - 1 | $\frac{SS_{between}}{df_{between}}$  | $\frac{MS_{between}}{MS_{within}}$  | area to right of $F_{k-1,n-k}$ |
| Within Group (Error)    | $\sum^{}_{k} \sum^{}_{i} (\bar{x}_{ik} -\bar{x}_{k} )^{2}$  | n - k | $\frac{SS_{within}}{df_{within}}$    |                                     |                                |
| Total                   | $\sum^{}_{k} \sum^{}_{i} (\bar{x}_{ik} -\bar{x} )^{2}$      | n - 1 |                                      |                                     |                                |

---
class: code90
# ANOVA Steps


```{r}
(grand.mean <- mean(hand$Bacterial.Counts))
(n <- nrow(hand))
(k <- length(unique(hand$Method)))
(ss.total <- sum((hand$Bacterial.Counts - grand.mean)^2))
```

---
# ANOVA Steps

.pull-left[
### Between Groups
```{r}
(df.between <- k - 1)
(ss.between <- sum(desc$n * 
		(desc$mean - grand.mean)^2))
(MS.between <- ss.between / df.between)
```
]
.pull-right[
### Within Groups
```{r}
(df.within <- n - k)
(ss.within <- ss.total - ss.between)
(MS.within <- ss.within / df.within)
```
]


---
# F Statistic


* $MS_T = `r prettyNum(MS.between, digits = 6)`$

* $MS_E = `r prettyNum(MS.within, digits = 6)`$

* Numerator df = 4 - 1 = 3

* Denominator df = 4(8 - 1) = 28.


```{r}
(f.stat <- 9960.64 / 1410.14)
1 - pf(f.stat, 3, 28)
```

P-value for $F_{3,28} \approx 0.0011$

---
# F Distribution

```{r}
DATA606::F_plot(df.numerator, df.denominator, cv = f.stat)
```

---
# Assumptions and Conditions

* To check the assumptions and conditions for ANOVA, always look at  the side-by-side boxplots.
	* Check for outliers within any group.
	* Check for similar spreads.
	* Look for skewness.
	* Consider re-expressing.
	
* Independence Assumption
	* Groups must be independent of each other.
	* Data within each group must be independent.
	* Randomization Condition
	
* Equal Variance Assumption
	* In ANOVA, we pool the variances.  This requires equal variances from each group:  Similar Spread Condition.

---
class: font120
# ANOVA in R

```{r}
aov.out <- aov(Bacterial.Counts ~ Method, data=hand)
summary(aov.out)
```

---
class: font120
# What Next? 

* P-value large -> Nothing left to say
* P-value small -> Which means are large and which means are small?
* We can perform a t-test to compare two of them.
* We assumed the standard deviations are all equal.
* Use $s_p$, for pooled standard deviations.
* Use the Students t-model, df = N - k.
* If we wanted to do a t-test for each pair:
	* P(Type I Error) = 0.05 for each test.
	* Good chance at least one will have a Type I error.
* **Bonferroni to the rescue!**
	* Adjust a to $\alpha/J$ where J is the number of comparisons.
	* 95% confidence (1 - 0.05) with 3 comparisons adjusts to $(1 - 0.05/3) \approx  0.98333$.
	* Use this adjusted value to find t**.

---
# Multiple Comparisons (no Bonferroni adjustment)

.code80[
```{r, fig.height=5, tidy=FALSE}
cv <- qt(0.05, df = 15)
tab <- describeBy(hand$Bacterial.Counts, group = hand$Method, mat = TRUE)
ggplot(hand, aes(x = Method, y = Bacterial.Counts)) + geom_boxplot() + 
	geom_errorbar(data = tab, aes(x = group1, y = mean, 
								  ymin = mean - cv * se, ymax = mean + cv * se), 
				  color = 'darkgreen', width = 0.5, size = 1) +
	geom_point(data = tab, aes(x = group1, y = mean), color = 'blue', size = 3)
```
]

---
# Multiple Comparisons (3 paired tests)

.code80[
```{r, fig.height=5, tidy=FALSE}
cv <- qt(0.05 / 3, df = 15)
tab <- describeBy(hand$Bacterial.Counts, group = hand$Method, mat = TRUE)
ggplot(hand, aes(x = Method, y = Bacterial.Counts)) + geom_boxplot() + 
	geom_errorbar(data = tab, aes(x = group1, y = mean, 
								  ymin = mean - cv * se, ymax = mean + cv * se), 
				  color = 'darkgreen', width = 0.5, size = 1) +
	geom_point(data = tab, aes(x = group1, y = mean), color = 'blue', size = 3)
```
]

---
# Multiple Comparisons (6 paired tests)

.code80[
```{r, fig.height=5, tidy=FALSE}
cv <- qt(0.05 / choose(4, 2), df = 15)
tab <- describeBy(hand$Bacterial.Counts, group = hand$Method, mat = TRUE)
ggplot(hand, aes(x = Method, y = Bacterial.Counts)) + geom_boxplot() + 
	geom_errorbar(data = tab, aes(x = group1, y = mean, 
								  ymin = mean - cv * se, ymax = mean + cv * se ), 
				  color = 'darkgreen', width = 0.5, size = 1) +
	geom_point(data = tab, aes(x = group1, y = mean), color = 'blue', size = 3)
```
]


---
class: left, font140
# One Minute Paper

Complete the one minute paper: 
`r params$one_minute_paper`

1. What was the most important thing you learned during this class?
2. What important question remains unanswered for you?
