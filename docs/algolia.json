[{"content":"DATA 606 Statistics \u0026amp;amp; ProbabilitySpring 2021  Announcements Be sure to check this page regularly for updates.\n","date":1620777600,"description":"","lastmod":"2021-05-12T00:00:00Z","objectID":"3976528693a0108357f4928017600865","permalink":"/","title":"Home"},{"content":"Your course grade will be determined by the following assignments:\n DAACS (6%) Participation (10%) Homework (18%) Labs (36%) Data Project (20%) Final exam (10%)  ","date":-62135596800,"description":"","objectID":"5d370553e45c580541e007200292c8d8","permalink":"/assignments/","title":"Assignments"},{"content":"Formative Assessments Formative assessments are a type of assessment that help students and teachers monitor student learning. These are low stakes assessments (i.e. you get credit for doing them, not based upon how you did). I will use the results to inform my instruction.\nPart 1 Complete this Google Form. The purpose of this survey is for me to get to know you better. There is no passing or failing, right or wrong answers. Please answer each section honestly. I will use the results in aggregate to inform the instruction in this class.\nPart 2 The Diagnostic Assessment and Achievement of College Skills (DAACS) is a formative assessment designed to provide you with information about key college skills. DAACS includes assessments in self-regulated learning, mathematics, reading, and writing. YOU ARE ONLY REQUIRED TO COMPLETE THE SELF-REGULATED LEARNING ASSESSMENT. This should take about 10 minutes to complete the assessment and there is no passing or failing. Once you are done, I encourage you to review the resources recommended to you. We will use the aggregated results in class. To get credit for this assignment:\n Go to my.daacs.net Create an account. Please use the email address entered in the Google form in Part 1. Complete the Self-Regulated Learning (SRL) assessment.  You will receive an email from me through DAACS inviting you to a course within DAACS. Please accept the invitation as this will be how I can verify you completed the assignment.\n","date":-62135596800,"description":"","objectID":"45b67ff810eb41ecfde988198c540404","permalink":"/assignments/daacs/","title":"DAACS"},{"content":"The final exam will be posted on Blackboard during the time indicated on the course schedule.\n","date":-62135596800,"description":"","objectID":"9c7245bec61480c346929e6d4a3619b4","permalink":"/assignments/final/","title":"Final Exam"},{"content":"The solutions to the practice problems are at the end of the book and do not need to be handed in. Graded assignments should use the provided R markdown templates provided below. Data for the homework assignments, and for within the chapters too, can be downloaded here. Or alternatively all the data is included in the openintro R packge (use the data(package = \u0026#39;openintro\u0026#39;) command to list all the datasets available in that package). Right click on the \u0026amp;ldquo;Template\u0026amp;rdquo; link and choose \u0026amp;ldquo;Save link as\u0026amp;hellip;\u0026amp;rdquo; to save the R markdown file to your computer. By default, the Rmarkdown files should generate PDFs. This is the preferred format since PDFs can be uploaded to Blackboard. See the software course page for instructions on installing LaTeX.\n Chapter 1 - Introduction to Data (Template) Chapter 2 - Summarizing Data (Template) Chapter 3 - Probability (Template) Chapter 4 - Distributions of Random Variables (Template) Chapter 5 - Foundations for Inference (Template) Chapter 6 - Inference for Categorical Data (Template) Chapter 7 - Inference for Numerical Data (Template) Chapter 8 - Introduction to Linear Regression (Template) Chapter 9 - Multiple and Logistic Regression (Template)  ","date":-62135596800,"description":"","objectID":"3c01518782c0c0dfdafd9bba2f2604ef","permalink":"/assignments/homework/","title":"Homework"},{"content":"These mini projects will have you explore statistical topics using R. You can use the startLab function in the DATA606 package to get started, or copy the templates from the links below. Please submit a PDF (preferred) or HTML file along with your Rmarkdown file. Be sure to answer all questions in lab, not just the on your own section. Labs should be submitted on Blackboard.\nIntroduction to R and RStudio (Template) Introduction to Data (Template) Probability (Template) Distributions of Random Variables (Template) Foundations for Statistical Inference Sampling Distributions (Template) Confidence Levels (Template)  Inference for Categorical Data (Template) Inference for Numerical Data (Template) Introduction to Linear Regression (Template) Multiple Linear Regerssion (Template)  ","date":-62135596800,"description":"","objectID":"a02f24d3fc8ea6850af297e53a13e989","permalink":"/assignments/labs/","title":"Labs"},{"content":"One Minute Papers A \u0026amp;ldquo;one minute paper\u0026amp;rdquo; (Angelo \u0026amp;amp; Cross, 1993) is a short written reflection to be completed after each class meetup. You are to answer two questions: 1) What was the most important thing you learned during this class? and 2) What important question remains unanswered for you? My goal is to give you a moment to reflect on the most important concepts presented were and to provide me with information about what concepts are still unclear. At the completion of each meetup (whether attended live or after watching the recording), complete this Google form.\nHomework Presentation You are responsible for presenting one practice homework problem during the semester. Please sign up as-soon-as possible as there are limited slots per week. Try to keep each presentation to five minutes or less. Sign-up on this Google Spreadsheet. You may present live during the Meetup or provide a prerecorded video. If you choose the latter, please provide the link in the Google Spreadsheet prior to the Meetup so I can include it in that weeks slide deck.\nSlack Please be an active participant in the Slack channel. In addition to being a good resource for asking and answer questions, I hope you begin to make connections with other students. Contribute at least one resource related to data science that you find and think would be useful to your fellow students. Please post it in the #resource channel.\n","date":-62135596800,"description":"","objectID":"4480c159d8f55584cfb98c013b898347","permalink":"/assignments/participation/","title":"Participation"},{"content":"  The purpose of the data project is for you to conduct a reproducible analysis with a data set of your choosing. There are two components to the project, the proposal, which will be graded on a pass/fail basis, and the final report. The outline for each of these are provided in the templates. When submitting the assignments, include the R Markdown file (change the name to include your last name, for example Bryer-Proposal.Rmd and Bryer-Project.Rmd) along with any supplementary files necessary to run the R Markdown file (e.g. data files, screenshots, etc.). Suggestions for possible data sources are included below, however you are free to use data not listed below. The only requirement is that you are allowed to share the data. Projects will be shared with others on this website so should be presented in a way that other students can reproduce your analysis.\nProject Proposal The proposal can be more informal using bullet points where necessary and include R code and output. You must address the following areas:\n Research question\n What are the cases, and how many are there?\n Describe the method of data collection.\n What type of study is this (observational/experiment)?\n Data Source: If you collected the data, state self-collected. If not, provide a citation/link.\n Response: What is the response variable, and what type is it (numerical/categorical)?\n Explanatory: What is the explanatory variable(s), and what type is it (numerical/categorival)?\n Relevant summary statistics\n Download project proposal template\n Download project template\n  Example data project proposal (Source Rmarkdown file)\n Final Project  You are required to attend ONLY ONE of those time slots. You will do your presentation, watch the other presentations, and provide peer feedback (will be shared anonymously afterward).  Click here to sign-up for a presentation slot. Please pick one timeslot. You need to stay for all presentations during that time as there will be a peer feedback form provided. There …","date":-62135596800,"description":"","objectID":"0eff5ebd45f0e03abd01b6215fb222f0","permalink":"/assignments/project/","title":"Project"},{"categories":["R"],"content":"  Welcome to DATA606! My name is Dr. Jason Bryer and I will be your instructor for this semester. I am an Assistant Professor and Associate Director in the Data Science and Information Systems department at CUNY SPS. Couple of important notes as you get started:\n The course syllabus located here: https://fall2021.data606.net/course-overview I will post all course materials there. Blackboard will be used primarily for submitting assignments. Please read the syllabus carefully! Send me any questions you may still have about the course. Complete this Google Form as soon as possible. I will use some of the data (in aggregate) in the meetup. Join the Slack channel by clicking here. This will be our primary mode of communication. For private communications, you can either send private Slack messages or email me at jason.bryer@sps.cuny.edu. Once you go through the syllabus, try starting Lab 1 as soon as you can. This will require you to install R and RStudio and will help get you get acquainted with R. See the software page for more information about the software we will use for this course. The best way to reach me is by Slack or email at jason.bryer@sps.cuny.edu. If you would prefer to talk on the phone or setup a Zoom session, it is best to suggest some times by email first. Our Meetups will be on Wednesdays from 8:30pm to 9:30pm. I expect everyone to attend or watch the Meetups. Important information will be shared during the meetups that will not be available in any other format. I am looking forward to getting to know everyone and a fantastic semester! Good luck!  ","date":1611532800,"description":"","lastmod":"2021-01-25T00:00:00Z","objectID":"f1e9cd0ea122e4891f9d4df33f0bfadc","permalink":"/blog/01-welcome-to-data606/","publishdate":"2021-01-25T00:00:00Z","tags":["Annoucement"],"title":"Welcome to DATA606!"},{"content":"","date":1620777600,"description":"","lastmod":"2021-05-12T00:00:00Z","objectID":"b0d8ccffb8d530bff08365a148a04ee6","permalink":"/blog/","title":"Announcements"},{"categories":["R","Meetups","Announcements"],"content":"Here is a recording of the course introduction Meetup. Click here to open the slides.\n ","date":1611878400,"description":"","lastmod":"2021-01-29T00:00:00Z","objectID":"4e8e94fe5f6d9019c9a08e034391ac3e","permalink":"/blog/draft/02-introductions/","publishdate":"2021-01-29T00:00:00Z","tags":["Annoucement"],"title":"Introductions"},{"categories":["R","Meetups","Announcements"],"content":"Here is a recording of the Intro to Data Meetup. Click here to open the slides.\n ","date":1612310400,"description":"","lastmod":"2021-02-03T00:00:00Z","objectID":"d6913b7a27490406ea5787d81e478eeb","permalink":"/blog/draft/2021-02-03-intro_to_data/","publishdate":"2021-02-03T00:00:00Z","tags":["Annoucement"],"title":"Intro to Data Meetup"},{"categories":["R","Meetups","Announcements"],"content":"Click here to open the slides.\n ","date":1612915200,"description":"","lastmod":"2021-02-10T00:00:00Z","objectID":"4eb71bac1ded9d9446092aaebe586c41","permalink":"/blog/draft/2021-02-10-summarizing_data/","publishdate":"2021-02-10T00:00:00Z","tags":["Annoucement"],"title":"Summarizing Data"},{"categories":["R","Meetups","Announcements"],"content":"Click here to open the slides.\n ","date":1613520000,"description":"","lastmod":"2021-02-17T00:00:00Z","objectID":"dbcae2171655485917927c2331952c40","permalink":"/blog/draft/2021-02-17-probability/","publishdate":"2021-02-17T00:00:00Z","tags":["Annoucement"],"title":"Probability"},{"categories":["R"],"content":"  To explore how R generates random numbers, we will use the rnorm function. This function draws a random number from a normal distribution with a mean = 0 and standard deviation = 1 (though these can be changed with the mean and sd parameters). With n = 1 we will get one random number.\nrnorm(n = 1) ## [1] 0.8305346 rnorm(n = 1) ## [1] -0.1843309 Each time you run the command you will get a different number. The set.seed function will sets a seed to the random number generator so that each subsequent run will produce the same number.\nset.seed(2112); rnorm(n = 1) ## [1] 0.9243372 set.seed(2112); rnorm(n = 1) ## [1] 0.9243372 Setting a different seed results in a different number.\nset.seed(2113); rnorm(n = 1) ## [1] 0.5499032 What are seeds?\nComputers are actually bad at random events. However, there are good algorithms that mimic random processes (hence psydo random). These algorithms work by starting with some initial value, a seed, and executing a complex algorithm that approximates randomization. The seed is often set to the current time in milliseconds. To visualize the random process, we will use the sample function to randomly select a number between 1 and 100. We will consider the ouput for the first 1,000 seeds.\nrandom_numbers \u0026amp;lt;- integer(1000) for(i in seq_len(length(random_numbers))) { set.seed(i) random_numbers[i] \u0026amp;lt;- sample(1:100, size = 1) } library(ggplot2) ggplot(data.frame(x = 1:100, y = random_numbers), aes(x = x, y = y)) + geom_point() + xlab(\u0026amp;#39;Seed\u0026amp;#39;) + ylab(\u0026amp;#39;Random Number\u0026amp;#39;) ","date":1613606400,"description":"","lastmod":"2021-02-18T00:00:00Z","objectID":"6d944f2a62c13786d0aa2451f1ab7fe2","permalink":"/blog/draft/2021-02-18-random_numbers_and_seeds/","publishdate":"2021-02-18T00:00:00Z","tags":["random numbers"],"title":"Random Numbers and Seeds in R"},{"categories":["R","Meetups","Announcements"],"content":"Click here to open the slides.\n ","date":1614124800,"description":"","lastmod":"2021-02-24T00:00:00Z","objectID":"f031c232c36fab5ce3da6129ce6ec9ea","permalink":"/blog/draft/2021-02-24-distributions1/","publishdate":"2021-02-24T00:00:00Z","tags":["Annoucement"],"title":"Distributions"},{"categories":["R"],"content":"  Quantile-quantile plots are a useful tool for determining whether a measure is normally distributed. From Wikipedia:\n  Q–Q (quantile-quantile) plot is a probability plot, which is a graphical method for comparing two probability distributions by plotting their quantiles against each other. First, the set of intervals for the quantiles is chosen. A point (x, y) on the plot corresponds to one of the quantiles of the second distribution (y-coordinate) plotted against the same quantile of the first distribution (x-coordinate). Thus the line is a parametric curve with the parameter which is the number of the interval for the quantile.\n  Let’s begin with a vector of values, mpg from the mtcars data frame. The plot below is a histogram of values, density of mpg in black, and normal distribution in blue.\ndata(mtcars) x \u0026amp;lt;- mtcars$mpg x \u0026amp;lt;- x[order(x)] # Order the vector ggplot(mtcars, aes(x = mpg)) + geom_histogram(aes(y = ..density..), bins = 10, fill = \u0026amp;#39;grey50\u0026amp;#39;) + geom_density() + geom_function(fun = dnorm, args = list(mean = mean(x), sd = sd(x)), color = \u0026amp;#39;blue\u0026amp;#39;) + xlim(mean(x) - 3 * sd(x), mean(x) + 3 * sd(x)) To calculate the theoretical quantiles, we start with a vector of length equal to the original data (i.e. n = 32 in this example). The ppoints generates a sequence of probability points that are equally distributed between 0 and 1.\n( points \u0026amp;lt;- ppoints(length(x)) ) ## [1] 0.015625 0.046875 0.078125 0.109375 0.140625 0.171875 0.203125 0.234375 ## [9] 0.265625 0.296875 0.328125 0.359375 0.390625 0.421875 0.453125 0.484375 ## [17] 0.515625 0.546875 0.578125 0.609375 0.640625 0.671875 0.703125 0.734375 ## [25] 0.765625 0.796875 0.828125 0.859375 0.890625 0.921875 0.953125 0.984375 Using the qnorm function we can calucate the quantile for each of these values.\n( y \u0026amp;lt;- qnorm(points) ) ## [1] -2.15387469 -1.67593972 -1.41779714 -1.22985876 -1.07751557 -0.94678176 ## [7] -0.83051088 -0.72451438 -0.62609901 -0.53340971 -0.44509652 -0.36012989 ## …","date":1614556800,"description":"","lastmod":"2021-03-01T00:00:00Z","objectID":"127bd6d11d5c11b675dbd47735a3741f","permalink":"/blog/draft/2021-03-01-qqplots/","publishdate":"2021-03-01T00:00:00Z","tags":["qqplots"],"title":"Quantile-Quantile Plots"},{"categories":["R","Meetups","Announcements"],"content":"Click here to open the slides. Univariate distribution relationships. Essence of calculus video series.\n Here is the R code from class:\nn \u0026amp;lt;- 5 p \u0026amp;lt;- 0.35 # p \u0026amp;lt;- .65 probs \u0026amp;lt;- dbinom(0:n, n, p) probs sum(probs) barplot(dbinom(0:n, n, p), names.arg=0:n) x \u0026amp;lt;- rnorm(100) ggplot(data.frame(x = x), aes(x = x)) + geom_histogram(bins = 10, fill = \u0026amp;#39;grey70\u0026amp;#39;) + geom_vline(xintercept = mean(x), color = \u0026amp;#39;blue\u0026amp;#39;) + geom_vline(xintercept = c(mean(x) - sd(x), mean(x) + sd(x)), color = \u0026amp;#39;darkgreen\u0026amp;#39;) ggplot(data.frame(x = x), aes(x = x)) + geom_histogram(aes(y = ..density..), bins = 10, fill = \u0026amp;#39;grey70\u0026amp;#39;) + geom_vline(xintercept = mean(x), color = \u0026amp;#39;blue\u0026amp;#39;) + geom_function(fun = dnorm) + geom_vline(xintercept = c(mean(x) - sd(x), mean(x) + sd(x)), color = \u0026amp;#39;darkgreen\u0026amp;#39;) ","date":1614729600,"description":"","lastmod":"2021-03-03T00:00:00Z","objectID":"03e9806e3cbe34ff77b25ac27c6b40f3","permalink":"/blog/draft/2021-03-03-distributions2/","publishdate":"2021-03-03T00:00:00Z","tags":["Annoucement"],"title":"Distributions Part 2"},{"categories":["R","Meetups","Announcements"],"content":"Click here to open the slides.\n ","date":1615334400,"description":"","lastmod":"2021-03-10T00:00:00Z","objectID":"b438d1f12fecfe307e311c2371c61082","permalink":"/blog/draft/2021-03-10-foundation_for_inference/","publishdate":"2021-03-10T00:00:00Z","tags":["Annoucement"],"title":"Foundation for Inference"},{"categories":["R","Meetups","Announcements"],"content":"Click here to open the slides.\n Here is the R script from class.\nlibrary(tidyverse) p_hat \u0026amp;lt;- 0.657 n \u0026amp;lt;- 680 + 105 # Create a table that mimics the resulting counts df \u0026amp;lt;- data.frame( Group = c(rep(\u0026amp;#39;Duke\u0026amp;#39;, 69 + 36), rep(\u0026amp;#39;American\u0026amp;#39;, 454+226)), Respone = c(rep(\u0026amp;#39;Yes\u0026amp;#39;, 69), rep(\u0026amp;#39;No\u0026amp;#39;, 36), rep(\u0026amp;#39;Yes\u0026amp;#39;, 454) , rep(\u0026amp;#39;No\u0026amp;#39;, 226) ) ) table(df$Group, df$Respone) # Verify the counts are the same # Estimate the bootstrap sample boots \u0026amp;lt;- numeric() for(i in 1:1000) { temp \u0026amp;lt;- df[sample(nrow(df), size = nrow(df), replace = TRUE),] temp2 \u0026amp;lt;- table(temp$Group, temp$Respone) %\u0026amp;gt;% prop.table(1) boots[i] \u0026amp;lt;- diff(temp2[,2]) } mean(boots) sd(boots) # 95% Confidence Interval c(mean(boots) - 1.96 * sd(boots), mean(boots) + 1.96 * sd(boots)) # Bootstrap distribution hist(boots) ","date":1615939200,"description":"","lastmod":"2021-03-17T00:00:00Z","objectID":"b9aa0438ff3dcf1eeead277319089160","permalink":"/blog/draft/2021-03-17-inference_for_categorical_variables/","publishdate":"2021-03-17T00:00:00Z","tags":["Annoucement"],"title":"Inference for Categorical Data"},{"categories":["R","Meetups","Announcements"],"content":"Click here to open the slides.\n Here is the R script from class.\nlibrary(tidyverse) library(reshape2) data(hsb2) head(hsb2) my_hsb2 \u0026amp;lt;- hsb2 %\u0026amp;gt;% select(id, read, write, math, science, socst) head(my_hsb2) nrow(my_hsb2) my_hsb2_melt \u0026amp;lt;- melt(my_hsb2, id.vars = \u0026amp;#39;id\u0026amp;#39;) head(my_hsb2_melt) nrow(my_hsb2_melt) ggplot(my_hsb2_melt, aes(x = variable, y = value)) + geom_boxplot() x \u0026amp;lt;- seq(-1, 1, by = 0.01) x plot(x, dt(x, df = 10), type = \u0026amp;#39;l\u0026amp;#39;) ","date":1616544000,"description":"","lastmod":"2021-03-24T00:00:00Z","objectID":"6c6cf5b26aca1a7a435666f05fbfb2de","permalink":"/blog/draft/2021-03-24-inference_for_numerical_variables/","publishdate":"2021-03-24T00:00:00Z","tags":["Annoucement"],"title":"Inference for Numerical Data"},{"categories":["R","Meetups","Announcements"],"content":"Click here to open the slides.\n ","date":1617753600,"description":"","lastmod":"2021-04-07T00:00:00Z","objectID":"6f0967293a289abbdef0820efe223410","permalink":"/blog/draft/2021-04-07-linear_regression/","publishdate":"2021-04-07T00:00:00Z","tags":["Annoucement"],"title":"Linear Regression"},{"categories":["R","Meetups","Announcements"],"content":"Click here to open the slides.\n ","date":1618358400,"description":"","lastmod":"2021-04-14T00:00:00Z","objectID":"9e25cfcea49419da78463a41d6c1e5f3","permalink":"/blog/draft/2021-04-14-linear_regression2/","publishdate":"2021-04-14T00:00:00Z","tags":["Annoucement"],"title":"Linear Regression Part 2"},{"categories":["R","Meetups","Announcements"],"content":"Click here to open the slides.\nShiny app to visualize interactions, simple main effects, simple slopes and model surfaces in 2-IV linear models\n Here is the R script for analyzing the tutorial dataset: library(openintro) library(ggplot2) data(\u0026amp;quot;tourism\u0026amp;quot;, package = \u0026amp;#39;openintro\u0026amp;#39;) # Question 8.21 ggplot(tourism, aes(x = visitor_count_tho)) + geom_histogram() ggplot(tourism, aes(x = tourist_spending)) + geom_histogram() ggplot(tourism, aes(x = visitor_count_tho, y = tourist_spending)) + geom_point() + geom_smooth(method = \u0026amp;#39;lm\u0026amp;#39;, se = FALSE, formula = y ~ x) + scale_x_log10() + scale_y_log10() lm.out \u0026amp;lt;- lm(visitor_count_tho ~ tourist_spending, data = tourism) summary(lm.out) ## ## Call: ## lm(formula = visitor_count_tho ~ tourist_spending, data = tourism) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1672.01 -377.84 3.28 410.00 2674.76 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026amp;gt;|t|) ## (Intercept) 636.75289 151.86868 4.193 0.000127 *** ## tourist_spending 1.49912 0.02466 60.786 \u0026amp;lt; 2e-16 *** ## --- ## Signif. codes: 0 \u0026amp;#39;***\u0026amp;#39; 0.001 \u0026amp;#39;**\u0026amp;#39; 0.01 \u0026amp;#39;*\u0026amp;#39; 0.05 \u0026amp;#39;.\u0026amp;#39; 0.1 \u0026amp;#39; \u0026amp;#39; 1 ## ## Residual standard error: 815.9 on 45 degrees of freedom ## Multiple R-squared: 0.988, Adjusted R-squared: 0.9877 ## F-statistic: 3695 on 1 and 45 DF, p-value: \u0026amp;lt; 2.2e-16 lm.out.log \u0026amp;lt;- lm(log(visitor_count_tho) ~ log(tourist_spending), data = tourism) summary(lm.out.log) ## ## Call: ## lm(formula = log(visitor_count_tho) ~ log(tourist_spending), ## data = tourism) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.49935 -0.14620 -0.01635 0.18520 0.58194 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026amp;gt;|t|) ## (Intercept) 4.36409 0.12413 35.16 \u0026amp;lt;2e-16 *** ## log(tourist_spending) 0.54839 0.01755 31.25 \u0026amp;lt;2e-16 *** ## --- ## Signif. codes: 0 \u0026amp;#39;***\u0026amp;#39; 0.001 \u0026amp;#39;**\u0026amp;#39; 0.01 \u0026amp;#39;*\u0026amp;#39; 0.05 \u0026amp;#39;.\u0026amp;#39; 0.1 \u0026amp;#39; \u0026amp;#39; 1 ## ## Residual standard error: 0.2813 on 45 degrees of freedom ## Multiple R-squared: 0.956, …","date":1618963200,"description":"","lastmod":"2021-04-21T00:00:00Z","objectID":"297080870259ad8202ccb746425197a8","permalink":"/blog/draft/2021-04-21-multiple_linear_regression/","publishdate":"2021-04-21T00:00:00Z","tags":["Annoucement"],"title":"Multiple Linear Regression"},{"categories":["R","Meetups","Announcements"],"content":" Click here to open the slides. Source code for the slides and Shiny apps Loess regression application   ","date":1619481600,"description":"","lastmod":"2021-04-27T00:00:00Z","objectID":"fb30ff40a51fc3e7904b0d08c01d52e5","permalink":"/blog/draft/2021-04-27-intro_to_shiny/","publishdate":"2021-04-27T00:00:00Z","tags":["Annoucement"],"title":"Intro to Shiny"},{"categories":["R","Meetups","Announcements"],"content":"Click here to open the slides.\nTo run the MLE shiny app, you need to first install the visualMLE package:\nremotes::install_github(\u0026amp;#39;jbryer/visualMLE\u0026amp;#39;) Then run this function:\nvisualMLE::shiny_mle()  ","date":1619568000,"description":"","lastmod":"2021-04-28T00:00:00Z","objectID":"e7047169f156f065efe20741db625695","permalink":"/blog/draft/2021-04-28-logistic_regression/","publishdate":"2021-04-28T00:00:00Z","tags":["Annoucement"],"title":"Maximum Likelihood Estimation and Logistic Regression"},{"categories":["R","Meetups","Announcements"],"content":"Click here to open the slides.\n ","date":1620172800,"description":"","lastmod":"2021-05-05T00:00:00Z","objectID":"8e71570a6d926927ebd05682e608270b","permalink":"/blog/draft/2021-05-05-bayesian_analysis/","publishdate":"2021-05-05T00:00:00Z","tags":["Annoucement"],"title":"Bayesian Analysis"},{"categories":["R","Meetups","Announcements"],"content":"Click here to open the slides. Have a great summer!\n ","date":1620777600,"description":"","lastmod":"2021-05-12T00:00:00Z","objectID":"76fb600f3572529b636a3cd9c700333d","permalink":"/blog/draft/2021-05-12-final_meetup/","publishdate":"2021-05-12T00:00:00Z","tags":["Annoucement"],"title":"Final Meetup"},{"content":"The following pages contain learning objectives and supplemental materials for each chapter/topic. Will will typically cover one chapter a week but some chapters/topics will require multiple weeks (e.g. distributions; linear regression; multiple and logistic regression) so be sure to consult the schedule.\n","date":1493483784,"description":"","lastmod":"2017-04-29T18:36:24+02:00","objectID":"7c2d84d0ea7945a506816e027d583e1e","permalink":"/chapters/","title":"Chapters"},{"content":"Bayesian Analysis Supplemental Readings  Chapter 17 of Learning Statistics with R (Navarro, version 0.6) Fitting a Model by Maximum Likelihood (Collier, 2013). Kruschke\u0026amp;rsquo;s website for Doing Bayesian Data Analysis Kruschke\u0026amp;rsquo;s blog Andrew Gelman\u0026amp;rsquo;s blog - Posts about bayesian statistics  Videos Rasmus Bååth\u0026amp;rsquo;s Introduction to Bayesian Data Analysis Video Series    John Kruschke\u0026amp;rsquo;s Video Series Bayesian Methods Interpret Data Better\n Bayesian Estimation Supersedes the t Test\n Precision is the goal\n ","date":1493483784,"description":"","lastmod":"2017-04-29T18:36:24+02:00","objectID":"a517dbb081e1a9b42b2de6fa985aecd6","permalink":"/chapters/bayesian/","publishdate":"2017-04-29T18:36:24+02:00","title":"Bayesian"},{"content":"MathJax.Hub.Config({ tex2jax: { inlineMath: [[\u0026#39;$\u0026#39;,\u0026#39;$\u0026#39;], [\u0026#39;\\\\(\u0026#39;,\u0026#39;\\\\)\u0026#39;]], displayMath: [[\u0026#39;$$\u0026#39;,\u0026#39;$$\u0026#39;], [\u0026#39;\\[\u0026#39;,\u0026#39;\\]\u0026#39;]], processEscapes: true, processEnvironments: true, skipTags: [\u0026#39;script\u0026#39;, \u0026#39;noscript\u0026#39;, \u0026#39;style\u0026#39;, \u0026#39;textarea\u0026#39;, \u0026#39;pre\u0026#39;], TeX: { equationNumbers: { autoNumber: \u0026#34;AMS\u0026#34; }, extensions: [\u0026#34;AMSmath.js\u0026#34;, \u0026#34;AMSsymbols.js\u0026#34;] } } });   Introduction to Data Learning Objectives  Identify the type of variables (e.g. numerical or categorical; discrete or continuous; ordered or not ordered). Identify the relationship between multiple variables (i.e. independent vs. dependent). Define variables that are not associated as independent. Be able to describe and identify the difference between observational and experimental studies. Distinguish between simple random, stratified, and cluster sampling, and recognize the benefits and drawbacks of choosing one sampling scheme over another. Identify the four principles of experimental design and recognize their purposes: control any possible con- founders, randomize into treatment and control groups, replicate by using a sufficiently large sample or repeating the experiment, and block any variables that might influence the response.  Supplemental Readings  OpenIntro Statistics slides  Videos OpenIntro provides a number of videos. You may find these helpful while reading the chapter.\nCase Study: Using Stents to Prevent Strokes\n Data Basics: Observations, Variable, and Data Matrices\n Data Collection Principles\n Observational Studies and Sampling Strategies\n Designing Experiments\n [Using Randomization to Analyze a Gender Discrimination Study](Using Randomization to Analyze a Gender Discrimination Study)\n ","date":1493483784,"description":"","lastmod":"2017-04-29T18:36:24+02:00","objectID":"977a4d2f551e653275d53b68323ce775","permalink":"/chapters/chapter1/","publishdate":"2017-04-29T18:36:24+02:00","title":"Chapter 1"},{"content":"MathJax.Hub.Config({ tex2jax: { inlineMath: [[\u0026#39;$\u0026#39;,\u0026#39;$\u0026#39;], [\u0026#39;\\\\(\u0026#39;,\u0026#39;\\\\)\u0026#39;]], displayMath: [[\u0026#39;$$\u0026#39;,\u0026#39;$$\u0026#39;], [\u0026#39;\\[\u0026#39;,\u0026#39;\\]\u0026#39;]], processEscapes: true, processEnvironments: true, skipTags: [\u0026#39;script\u0026#39;, \u0026#39;noscript\u0026#39;, \u0026#39;style\u0026#39;, \u0026#39;textarea\u0026#39;, \u0026#39;pre\u0026#39;], TeX: { equationNumbers: { autoNumber: \u0026#34;AMS\u0026#34; }, extensions: [\u0026#34;AMSmath.js\u0026#34;, \u0026#34;AMSsymbols.js\u0026#34;] } } });   Summarizing Data Learning Outcomes  Use appropriate visualizations for different types of data (e.g. histogram, barplot, scatterplot, boxplot, etc.). Use different measures of center and spread and be able to describe the robustness of different statistics. Describe the shape of distributions vis-a-vis histograms and boxplots. Create and intepret contingency and frequency tables (one- and two-way tables).  Supplemental Readings  OpenIntro Statistics slides ggplot2 - ggplot2 is an R package by Wickham that implements the grammer of graphics (Wilkinson, 2005) in R. I will frequently make use of the graphing framework throughout the course and is worth learning. Visualizing Likert Data - An R package for visualizing Likert scale data built on the ggplot2 framework. Quick-R base graphics - Covers many of the visualizations using R\u0026amp;rsquo;s base graphics.  Videos Summarizing and Graphing Numerical Data\n Exploring Categorical Data\n Note about Pie Charts There is only one pie chart in OpenIntro Statistics (Diez, Barr, \u0026amp;amp; ??etinkaya-Rundel, 2015, p. 48). Consider the following three pie charts that represent the preference of five different colors. Is there a difference between the three pie charts? This is probably a difficult to answer.\nHowever, consider the bar plot below. Here, we cleary see there is a difference between the ratio of the three colors. As John Tukey famously said:\n There is no data that can be displayed in a pie chart that cannot better be displayed in some other type of chart\n Source: https://en.wikipedia.org/wiki/Pie_chart.\n","date":1493483784,"description":"","lastmod":"2017-04-29T18:36:24+02:00","objectID":"6cbb9806e608be3f8e29a6400e96839b","permalink":"/chapters/chapter2/","publishdate":"2017-04-29T18:36:24+02:00","title":"Chapter 2"},{"content":"MathJax.Hub.Config({ tex2jax: { inlineMath: [[\u0026#39;$\u0026#39;,\u0026#39;$\u0026#39;], [\u0026#39;\\\\(\u0026#39;,\u0026#39;\\\\)\u0026#39;]], displayMath: [[\u0026#39;$$\u0026#39;,\u0026#39;$$\u0026#39;], [\u0026#39;\\[\u0026#39;,\u0026#39;\\]\u0026#39;]], processEscapes: true, processEnvironments: true, skipTags: [\u0026#39;script\u0026#39;, \u0026#39;noscript\u0026#39;, \u0026#39;style\u0026#39;, \u0026#39;textarea\u0026#39;, \u0026#39;pre\u0026#39;], TeX: { equationNumbers: { autoNumber: \u0026#34;AMS\u0026#34; }, extensions: [\u0026#34;AMSmath.js\u0026#34;, \u0026#34;AMSsymbols.js\u0026#34;] } } });   Probability Learning Outcomes  Define trial, outcome, and sample space. Define and describe the law of large numbers. Distinguish disjoint (also called mutually exclusive) and independent events. Use Venn diagrams to represent events and their probabilities. Describe probability distributions. Distinguish between marginal and conditional probabilities. Use tree diagrams and/or Bayes Theorem to calculate conditional probabilities and probabilities of intersection of non-independent events. The expected value of a discrete random variable is computed by adding each outcome weighted by its probability.\n$$ E(X)=\\mu=\\sum_{i=1}^{k}{{x}_{i}P\\left(X={x}_{i}\\right)} $$ The variance of a discrete random variable is computed by adding each squared deviation of an outcome from the expected value weighted by its probability. The standard deviation is the square root of the variance.\n$$ Var(X)={\\sigma}^{2}=\\sum_{i=1}^{k}{{\\left({x}_{i}-\\mu\\right)}P\\left(X={x}_{i}\\right) } $$ The average of a linear combination of discrete random variables is computed as the sum of their averages, weighted by the constant multipliers. The variance of a linear combination of independent discrete random variables is computed as the sum of their variances, weighted by the square of the constant multipliers. The distribution of a continuous random variable is described by the probability density function. The total area under the density curve is 1. Probabilities under the density curve can be calculated as the area under the curve. The probability of a continuous random variable being exactly equal to a value is 0, since there is no area under the curve at a given location. …","date":1493483784,"description":"","lastmod":"2017-04-29T18:36:24+02:00","objectID":"6853b787355469666e72a1c8e0433958","permalink":"/chapters/chapter3/","publishdate":"2017-04-29T18:36:24+02:00","title":"Chapter 3"},{"content":"MathJax.Hub.Config({ tex2jax: { inlineMath: [[\u0026#39;$\u0026#39;,\u0026#39;$\u0026#39;], [\u0026#39;\\\\(\u0026#39;,\u0026#39;\\\\)\u0026#39;]], displayMath: [[\u0026#39;$$\u0026#39;,\u0026#39;$$\u0026#39;], [\u0026#39;\\[\u0026#39;,\u0026#39;\\]\u0026#39;]], processEscapes: true, processEnvironments: true, skipTags: [\u0026#39;script\u0026#39;, \u0026#39;noscript\u0026#39;, \u0026#39;style\u0026#39;, \u0026#39;textarea\u0026#39;, \u0026#39;pre\u0026#39;], TeX: { equationNumbers: { autoNumber: \u0026#34;AMS\u0026#34; }, extensions: [\u0026#34;AMSmath.js\u0026#34;, \u0026#34;AMSsymbols.js\u0026#34;] } } });   Distributions of Random Variables Learning Outcomes  Define the standardized (Z) score of a data point as the number of standard deviations it is away from the mean: $Z = \\frac{x - \\mu}{\\sigma}$. Use the Z score  if the distribution is normal: to determine the percentile score of a data point (using technology or normal probability tables) regardless of the shape of the distribution: to assess whether or not the particular observation is considered to be unusual (more than 2 standard deviations away from the mean)   Depending on the shape of the distribution determine whether the median would have a negative, positive, or 0 Z score. Assess whether or not a distribution is nearly normal using the 68-95-99.7% rule or graphical methods such as a normal probability plot.  Reading: Section 4.1 of OpenIntro Statistics Test yourself: True/False: In a right skewed distribution the Z score of the median is positive.   If X is a random variable that takes the value 1 with probability of success $p$ and 0 with probability of success $1-p$, then $X$ is a Bernoulli random variable. The geometric distribution is used to describe how many trials it takes to observe a success. Define the probability of finding the first success in the $n^{th}$ trial as $(1-p)^{n-1}p$.  $\\mu = \\frac{1}{p}$ $\\sigma^2 = \\frac{1-p}{p^2}$ $\\sigma = \\sqrt{\\frac{1-p}{p^2}}$   Determine if a random variable is binomial using the four conditions:  The trials are independent. The number of trials, n, is fixed. Each trial outcome can be classified as a success or failure. The probability of a success, p, is the same for each trial.   Calculate the number of possible scenarios for obtaining …","date":1493483784,"description":"","lastmod":"2017-04-29T18:36:24+02:00","objectID":"491d38d28bd6f5b4c446002688d35be6","permalink":"/chapters/chapter4/","publishdate":"2017-04-29T18:36:24+02:00","title":"Chapter 4"},{"content":"MathJax.Hub.Config({ tex2jax: { inlineMath: [[\u0026#39;$\u0026#39;,\u0026#39;$\u0026#39;], [\u0026#39;\\\\(\u0026#39;,\u0026#39;\\\\)\u0026#39;]], displayMath: [[\u0026#39;$$\u0026#39;,\u0026#39;$$\u0026#39;], [\u0026#39;\\[\u0026#39;,\u0026#39;\\]\u0026#39;]], processEscapes: true, processEnvironments: true, skipTags: [\u0026#39;script\u0026#39;, \u0026#39;noscript\u0026#39;, \u0026#39;style\u0026#39;, \u0026#39;textarea\u0026#39;, \u0026#39;pre\u0026#39;], TeX: { equationNumbers: { autoNumber: \u0026#34;AMS\u0026#34; }, extensions: [\u0026#34;AMSmath.js\u0026#34;, \u0026#34;AMSsymbols.js\u0026#34;] } } });   Foundations for Inference Learning Outcomes  Define sample statistic as a point estimate for a population parameter, for example, the sample proportion is used to estimate the population proportion, and note that point estimate and sample statistic are synonymous. Recognize that point estimates (such as the sample proportion) will vary from one sample to another, and define this variability as sampling variation. Calculate the sampling variability of the proportion, the standard error, as $SE = \\sqrt{\\frac{p(1-p)}{n}}$, where $p$ is the population proportion.  Note that when the population proportion $p$ is not known (almost always), this can be estimated using the sample proportion, $SE = \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}$.   Standard error measures the variability in point estimates from different samples of the same size and from the same population, i.e. measures the sampling variability. Recognize that when the sample size increases we would expect the sampling variability to decrease.  Conceptually: Imagine taking many samples from the population. When sample sizes are large the sample proportion will be much more consistent across samples than when the sample sizes are small. Mathematically: $SE = ???$, when $n$ increases, $SE$ will decrease since $n$ is in the denominator.   Notice that sampling distributions of point estimates coming from samples that don\u0026amp;rsquo;t meet the required conditions for the CLT (about sample size and independence) will not be normal. Define a confidence interval as the plausible range of values for a population parameter. Define the confidence level as the percentage of random samples which yield confidence …","date":1493483784,"description":"","lastmod":"2017-04-29T18:36:24+02:00","objectID":"665696096ee4ebfcc1648093e3c55619","permalink":"/chapters/chapter5/","publishdate":"2017-04-29T18:36:24+02:00","title":"Chapter 5"},{"content":"MathJax.Hub.Config({ tex2jax: { inlineMath: [[\u0026#39;$\u0026#39;,\u0026#39;$\u0026#39;], [\u0026#39;\\\\(\u0026#39;,\u0026#39;\\\\)\u0026#39;]], displayMath: [[\u0026#39;$$\u0026#39;,\u0026#39;$$\u0026#39;], [\u0026#39;\\[\u0026#39;,\u0026#39;\\]\u0026#39;]], processEscapes: true, processEnvironments: true, skipTags: [\u0026#39;script\u0026#39;, \u0026#39;noscript\u0026#39;, \u0026#39;style\u0026#39;, \u0026#39;textarea\u0026#39;, \u0026#39;pre\u0026#39;], TeX: { equationNumbers: { autoNumber: \u0026#34;AMS\u0026#34; }, extensions: [\u0026#34;AMSmath.js\u0026#34;, \u0026#34;AMSsymbols.js\u0026#34;] } } });   Inference for Categorical Data Learning Outcomes  Define population proportion $p$ (parameter) and sample proportion $\\hat{p}$ (point estimate). Calculate the sampling variability of the proportion, the standard error, as [ SE = \\sqrt{\\frac{p(1-p)}{n}}, ] where $p$ is the population proportion.  Note that when the population proportion $p$ is not known (almost always), this can be estimated using the sample proportion, $SE = \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}$.   Recognize that the Central Limit Theorem (CLT) is about the distribution of point estimates, and that given certain conditions, this distribution will be nearly normal.  In the case of the proportion the CLT tells us that if \\  the observations in the sample are independent, \\ the sample size is sufficiently large (checked using the success/failure condition: $np \\ge 10$ and $n(1-p) \\ge 10$), \\\nthen the distribution of the sample proportion will be nearly normal, centered at the true population proportion and with a standard error of $\\sqrt{\\frac{p(1-p)}{n}}$. [ \\hat{p} \\sim N \\left( mean = p, SE = \\sqrt{\\frac{p(1-p)}{n}} \\right) ]     Note that if the CLT doesn?t apply and the sample proportion is low (close to 0) the sampling distribution will likely be right skewed, if the sample proportion is high (close to 1) the sampling distribution will likely be left skewed. Remember that confidence intervals are calculated as [ \\text{point estimate} \\pm \\text{margin of error} ] and test statistics are calculated as [ \\text{test statistic =} \\frac{\\text{point estimate - null value}}{\\text{standard error}} ] Note that the standard error calculation for the confidence interval and the hypothesis …","date":1493483784,"description":"","lastmod":"2017-04-29T18:36:24+02:00","objectID":"a17d388604877dfd35830937e10ea88a","permalink":"/chapters/chapter6/","publishdate":"2017-04-29T18:36:24+02:00","title":"Chapter 6"},{"content":"MathJax.Hub.Config({ tex2jax: { inlineMath: [[\u0026#39;$\u0026#39;,\u0026#39;$\u0026#39;], [\u0026#39;\\\\(\u0026#39;,\u0026#39;\\\\)\u0026#39;]], displayMath: [[\u0026#39;$$\u0026#39;,\u0026#39;$$\u0026#39;], [\u0026#39;\\[\u0026#39;,\u0026#39;\\]\u0026#39;]], processEscapes: true, processEnvironments: true, skipTags: [\u0026#39;script\u0026#39;, \u0026#39;noscript\u0026#39;, \u0026#39;style\u0026#39;, \u0026#39;textarea\u0026#39;, \u0026#39;pre\u0026#39;], TeX: { equationNumbers: { autoNumber: \u0026#34;AMS\u0026#34; }, extensions: [\u0026#34;AMSmath.js\u0026#34;, \u0026#34;AMSsymbols.js\u0026#34;] } } });   Inference for Numerical Data Learning Outcomes  Use the $t$-distribution for inference on a single mean, difference of paired (dependent) means, and difference of independent means. Explain why the $t$-distribution helps make up for the additional variability introduced by using $s$ (sample standard deviation) in calculation of the standard error, in place of $\\sigma$ (population standard deviation). Describe how the $t$-distribution is different from the normal distribution, and what ?heavy tail? means in this context. Note that the $t$-distribution has a single parameter, degrees of freedom, and as the degrees of freedom increases this distribution approaches the normal distribution. Use a $t$-statistic, with degrees of freedom $df = n - 1$ for inference for a population mean:  Standard error: $SE = \\frac{s}{\\sqrt{n}}$ Confidence interval: $\\bar{x} \\pm t_{df}^\\star SE$ Hypothesis test: $T_{df} = \\frac{\\bar{x} - \\mu}{SE}$ \\end{itemize}   Describe how to obtain a p-value for a $t$-test and a critical $t$-score ($t^\\star_{df}$) for a confidence interval. Define observations as paired if each observation in one dataset has a special correspondence or connection with exactly one observation in the other data set. Carry out inference for paired data by first subtracting the paired observations from each other, and then treating the set of differences as a new numerical variable on which to do inference (such as a confidence interval or hypothesis test for the average difference). Calculate the standard error of the difference between means of two paired (dependent) samples as $SE = \\frac{s_{diff}}{\\sqrt{n_{diff}}}$ and use this standard error in …","date":1493483784,"description":"","lastmod":"2017-04-29T18:36:24+02:00","objectID":"89506b59c5a9eecedc67ff417170a946","permalink":"/chapters/chapter7/","publishdate":"2017-04-29T18:36:24+02:00","title":"Chapter 7"},{"content":"MathJax.Hub.Config({ tex2jax: { inlineMath: [[\u0026#39;$\u0026#39;,\u0026#39;$\u0026#39;], [\u0026#39;\\\\(\u0026#39;,\u0026#39;\\\\)\u0026#39;]], displayMath: [[\u0026#39;$$\u0026#39;,\u0026#39;$$\u0026#39;], [\u0026#39;\\[\u0026#39;,\u0026#39;\\]\u0026#39;]], processEscapes: true, processEnvironments: true, skipTags: [\u0026#39;script\u0026#39;, \u0026#39;noscript\u0026#39;, \u0026#39;style\u0026#39;, \u0026#39;textarea\u0026#39;, \u0026#39;pre\u0026#39;], TeX: { equationNumbers: { autoNumber: \u0026#34;AMS\u0026#34; }, extensions: [\u0026#34;AMSmath.js\u0026#34;, \u0026#34;AMSsymbols.js\u0026#34;] } } });   Introduction to Linear Regression Learning Outcomes  Define the explanatory variable as the independent variable (predictor), and the response variable as the dependent variable (predicted). Plot the explanatory variable ($x$) on the x-axis and the response variable ($y$) on the y-axis, and fit a linear regression model $y = \\beta_0 + \\beta_1 x$ where $\\beta_0$ is the intercept, and $\\beta_1$ is the slope.  Note that the point estimates (estimated from observed data) for $\\beta_0$ and $\\beta_1$ are $b_0$ and $b_1$, respectively.   When describing the association between two numerical variables, evaluate  direction: positive ($x \\uparrow, y \\uparrow$), negative ($x \\downarrow, y \\uparrow$) form: linear or not strength: determined by the scatter around the underlying relationship   Define correlation as the \\emph{linear} association between two numerical variables.  Note that a relationship that is nonlinear is simply called an association.   Note that correlation coefficient ($r$, also called Pearson\u0026amp;rsquo;s $r$) the following properties:  the magnitude (absolute value) of the correlation coefficient measures the strength of the linear association between two numerical variables the sign of the correlation coefficient indicates the direction of association the correlation coefficient is always between -1 and 1, inclusive, with -1 indicating perfect negative linear association, +1 indicating perfect positive linear association, and 0 indicating no \\emph{linear} relationship the correlation coefficient is unitless since the correlation coefficient is unitless, it is not affected by changes in the center or scale of either variable (such as unit …","date":1493483784,"description":"","lastmod":"2017-04-29T18:36:24+02:00","objectID":"f08b0e0a16eb2a4f1723169a7d8ab446","permalink":"/chapters/chapter8/","publishdate":"2017-04-29T18:36:24+02:00","title":"Chapter 8"},{"content":"MathJax.Hub.Config({ tex2jax: { inlineMath: [[\u0026#39;$\u0026#39;,\u0026#39;$\u0026#39;], [\u0026#39;\\\\(\u0026#39;,\u0026#39;\\\\)\u0026#39;]], displayMath: [[\u0026#39;$$\u0026#39;,\u0026#39;$$\u0026#39;], [\u0026#39;\\[\u0026#39;,\u0026#39;\\]\u0026#39;]], processEscapes: true, processEnvironments: true, skipTags: [\u0026#39;script\u0026#39;, \u0026#39;noscript\u0026#39;, \u0026#39;style\u0026#39;, \u0026#39;textarea\u0026#39;, \u0026#39;pre\u0026#39;], TeX: { equationNumbers: { autoNumber: \u0026#34;AMS\u0026#34; }, extensions: [\u0026#34;AMSmath.js\u0026#34;, \u0026#34;AMSsymbols.js\u0026#34;] } } });   Multiple and Logistic Regression Learning Outcomes  Define the multiple linear regression model as $$\\hat{y} = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\cdots + \\beta_k x_k$$ where there are $k$ predictors (explanatory variables). Interpret the estimate for the intercept ($b_0$) as the expected value of $y$ when all predictors are equal to 0, on average. Interpret the estimate for a slope (say $b_1$) as \u0026amp;ldquo;All else held constant, for each unit increase in $x_1$, we would expect $y$ to increase/decrease on average by $b_1$.\u0026amp;rdquo; Define collinearity as a high correlation between two independent variables such that the two variables contribute redundant information to the model \u0026amp;ndash; which is something we want to avoid in multiple linear regression. Note that $R^2$ will increase with each explanatory variable added to the model, regardless of whether or not the added variables is a meaningful predictor of the response variable. Therefore we use adjusted $R^2$, which applies a penalty for the number of predictors included in the model, to better assess the strength of a multiple linear regression model: $$R^2 = 1 - \\frac{Var(e_i) / (n - k - 1)}{Var(y_i) / (n - 1)}$$ where $Var(e_i)$ measures the variability of residuals ($SS_{Err}$), $Var(y_i)$ measures the total variability in observed $y$ ($SS_{Tot}$), $n$ is the number of cases and $k$ is the number of predictors.  Note that adjusted $R^2$ will only increase if the added variable has a meaningful contribution to the amount of explained variability in $y$, i.e. if the gains from adding the variable exceeds the penalty.   Define model selection as identifying the best model for predicting a …","date":1493483784,"description":"","lastmod":"2017-04-29T18:36:24+02:00","objectID":"8993e4c1752ea23383ceeac21ea88fde","permalink":"/chapters/chapter9/","publishdate":"2017-04-29T18:36:24+02:00","title":"Chapter 9"},{"content":"Instructor: Jason Bryer, Ph.D.\nClass Meetup: Wednesday 8:30pm to 9:30pm\nOffice Hours: Friday 12pm to 1pm \u0026amp;amp; by appointment\nEmail: jason.bryer@cuny.edu\nCourse Description This course covers basic techniques in probability and statistics that are important in the field of data analytics. Discrete probability models, sampling from infinite and finite populations, statistical distributions, basic Bayesian statistics, and non-parametric statistical techniques for categorical data are covered in this course. Each of these statistical concepts will be applied in a variety of real-world scenarios through the use of case studies and customized data sets.\nCourse Learning Outcomes: By then end of the course, students should be able to:\n Understand the foundations of probability theory and perform basic probability calculations. Build basic stochastic models for commonly encountered business problems. Model situations involving uncertainty using appropriate probability distributions and conditional techniques. Explore and summarize data using descriptive statistics. Test hypotheses using classical and modern computational techniques. Construct estimators and calculate intervals using classical and modern computational techniques. Perform basic Bayesian statistical techniques for estimation and testing hypotheses.  Program Learning Outcomes addressed by the course:  Business Understanding. Learn when probabilistic techniques apply to certain categories of business problems, discuss the sorts of solutions that are possible, and understand the limitations of these techniques. Foundational Math Skills. Explore and analyze data, build probabilistic and statistical models, construct estimators, and test hypotheses. Predictive Modeling. Learn foundational techniques that underlie predictive modeling algorithms, such as Naïve Bayes. Presentation. Complete and submit collaborative assignments using techniques from the course.  How is this course relevant for data analytics …","date":1508253975,"description":"","lastmod":"2017-10-17T15:26:15Z","objectID":"cfc5446e1f8415b341d7c4413534fb72","permalink":"/course-overview/","title":"Syllabus"},{"content":"Jason Bryer, Ph.D.\nEmail: jason.bryer@cuny.edu\nI am currently an Assistant Professor in Data Science and Information Systems at the City University of New York. Additionally, I am a consultant with Cornell University where he has developed a research and data collection platform for New York State’s Office of Special Education (https://data.osepartnership.org). Prior to joining CUNY, I was Executive Director at Excelsior College where he has served as Principal Investigator of the FIPSE First in the World grant to develop and research the Diagnostic Assessment and Achievement of College Skills along with supporting research and evaluation of other grants at the institution. My research interests include quasi-experimental designs with an emphasis in propensity score analysis, data systems to support formative assessment, and the use of open source software for conducting reproducible research. I have authored of over a dozen R packages, including three related to conducting propensity score analyses. When I\u0026amp;rsquo;m not crunching numbers, I am a photographer and proud dad to three boys.\nContact Office Hours (Zoom is preferred): By appointment. You\u0026amp;rsquo;re encouraged to schedule an appointment and I have time nearly everyday. You are also encouraged to ask us questions on Slack. If you wish to ask a question in private, you can email me directly.\nFor the most part, you can expect me to respond to questions by email within 24 hours. If you do not hear back from me within 48 hours of sending an email, please resend your message. I will be checking in on the course regularly, just about every day and likely several times each day. Please do not hesitate to ask if you have questions or concerns.\n","date":1508253975,"description":"","lastmod":"2017-10-17T15:26:15Z","objectID":"512c9825b08dff80c30cf7d99a1aaa09","permalink":"/course-overview/instructor/","publishdate":"2017-10-17T15:26:15Z","title":"Instructor"},{"content":"  These are supplemental materials. Click to download.\n Chapter 28_Anova.pdf Cheatsheets_2019.pdf Classical_Machine_Learning.JPG ggplot_aesthetics_cheatsheet.png Kruschke-Liddell2018_Article_BayesianDataAnalysisForNewcome.pdf R_Syntax_Comparison.jpeg stats_handout.pdf Textbooks  lsr-0.6.pdf os4.pdf ProbStatBook.pdf Supplemental  OpenIntro_extra_interaction_effects.pdf OpenIntro_extra_nonlinear_relationships.pdf OpenIntro_handout.pdf os2_extra_inference_guide.pdf os2_prob_tables.pdf os4_tablet.pdf   Thirteen Ways to Look at the Correlation Coefficient.pdf What_Is_Data_Science.pdf WhatisDataScienceFinalMay162018.pdf When to use what test.pdf  ","date":-62135596800,"description":"Materials","objectID":"09f629956ea0d2c95e3f873947fd9130","permalink":"/course-overview/materials/","title":"Materials"},{"content":" NOTE: I am aware that Daum Equation Editor has not been updated a long while and may no longer be supported on may platforms. I have not yet found a replacement as good as Daum, however have a look at this Wikipedia page on formula editors for a comprehnsive list of available software.\nOccasionally you will need to type equations in homework and labs. R Markdown supports LaTeX style equations using the MathJax javascript library. I do not expect you to learn LaTeX for this course. Instead, I recommend using the free application Daum Equation Editor. It availabe online, as a Google Chrome Extension, or as a standalone Mac Application.\nCreating Equations with Daum Equation Editor Occasionally you will need to type equations in homework and labs. R Markdown supports LaTeX style equations using the MathJax javascript library. I do not expect you to learn LaTeX for this course. Instead, I recommend using the free application Daum Equation Editor. It availabe online, as a Google Chrome Extension. With the editor, you can enter equations using menus.\nOnce done, copy and paste the LaTeX code at the bottom into your R Markdown file between two dollar signs (i.e. $), and the quation will be rendered by the web browser.\n$$ f\\left( x|\\mu ,\\sigma \\right) =\\frac { 1 }{ \\sigma \\sqrt { 2\\pi } } { e }^{ -\\frac { { \\left( x-\\mu \\right) }^{ 2 } }{ { 2\\sigma }^{ 2 } } } $$\n","date":-62135596800,"description":"","objectID":"673c11b5b279259804dddce55ecc36ce","permalink":"/course-overview/mathjax/","title":"Math Equations"},{"content":"   There will be weekly meetups. You are encouraged to attend as many as you can but recordings will generally be availabe the day after the meetup.\nJoin Zoom Meeting: https://zoom.us/my/jbryer\nMeeting ID: 626 617 3127\n+16465588656,,6266173127# US (New York)\nPhone Number: +1 646 558 8656 US (New York)\nFind your local number: https://us02web.zoom.us/u/kn00x9C6p\nPlease note: Students who participate in this class with their camera on or use a profile image are agreeing to have their video or image recorded solely for the purpose of creating a record for students enrolled in the class to refer to, including those enrolled students who are unable to attend live. If you are unwilling to consent to have your profile or video image recorded, be sure to keep your camera off and do not use a profile image. Likewise, students who un-mute during class and participate orally are agreeing to have their voices recorded. If you are not willing to consent to have your voice recorded during class, you will need to keep your mute button activated and communicate exclusively using the “chat” feature, which allows students to type questions and comments live.\nPresentation Signup Sheet\nOne Minute Paper - Complete this Google form after each class meetup (whether attended live or watched the recording).\n  Date  StartTime  Topic  Resources      Wed, Aug 25, 2021  8:30 pm  Intro to the Course     Wed, Sep 01, 2021  8:30 pm  Intro to Data     Wed, Sep 08, 2021  8:30 pm  Summarizing Data     Wed, Sep 15, 2021  8:30 pm  Probability     Wed, Sep 22, 2021  8:30 pm  Distributions     Wed, Sep 29, 2021  8:30 pm  Foundation for Inference     Wed, Oct 06, 2021  8:30 pm  Inference for Categorical Data     Wed, Oct 13, 2021  8:30 pm  Inference for Numerical Data     Wed, Oct 20, 2021  8:30 pm  Linear Regression     Wed, Oct 27, 2021  8:30 pm  Linear Regression (cont.)     Wed, Nov 03, 2021  8:30 pm  Multiple Regression     Wed, Nov 10, 2021  8:00 pm  Logistic Regression     Wed, Nov 17, 2021  8:30 pm …","date":-62135596800,"description":"Meetups","objectID":"e8b66eb3c8b418edb582a1ad7d27d6df","permalink":"/course-overview/meetups/","title":"Meetups"},{"content":"  Note: Schedule is subject to change. Last updated July 26, 2021 10:35AM.\nCUNY SPS Academic Calendar\n document.addEventListener(\u0026#39;DOMContentLoaded\u0026#39;, function() { var calendarEl = document.getElementById(\u0026#39;calendar\u0026#39;); var calendar = new FullCalendar.Calendar(calendarEl, { initialDate: \u0026#39;2021-08-01\u0026#39;, initialView: \u0026#39;dayGridMonth\u0026#39;, headerToolbar: { left: \u0026#39;prev,next today\u0026#39;, center: \u0026#39;title\u0026#39;, right: \u0026#39;dayGridMonth,timeGridWeek,timeGridDay,listWeek\u0026#39; }, height: \u0026#39;auto\u0026#39;, navLinks: true, // can click day/week names to navigate views editable: true, selectable: true, selectMirror: true, nowIndicator: true, events: [ { title: \u0026#34;Chapter 1 - Intro to Data, R, and Rstudio\u0026#34;, url: \u0026#34;/chapters/chapter1/\u0026#34;, start: \u0026#39;2021-08-25\u0026#39;, end: \u0026#39;2021-09-06\u0026#39; }, { title: \u0026#34;Chatper 2 - Summarizing Data\u0026#34;, url: \u0026#34;/chatpers/chapter2/\u0026#34;, start: \u0026#39;2021-09-06\u0026#39;, end: \u0026#39;2021-09-13\u0026#39; }, { title: \u0026#34;Chapter 3 - Probability\u0026#34;, url: \u0026#34;/chapters/chapter3\u0026#34;, start: \u0026#39;2021-09-13\u0026#39;, end: \u0026#39;2021-09-20\u0026#39; }, { title: \u0026#34;Chapter 4 - Distributions\u0026#34;, url: \u0026#34;/chapters/chapter4\u0026#34;, start: \u0026#39;2021-09-20\u0026#39;, end: \u0026#39;2021-09-27\u0026#39; }, { title: \u0026#34;Chatper 5 - Foundation for Inference\u0026#34;, url: \u0026#34;/chapters/chapter5\u0026#34;, start: \u0026#39;2021-09-27\u0026#39;, end: \u0026#39;2021-10-04\u0026#39; }, { title: \u0026#34;Chapter 6 - Inference for Categorical Data\u0026#34;, url: \u0026#34;/chapters/chapter6\u0026#34;, start: \u0026#39;2021-10-04\u0026#39;, end: \u0026#39;2021-10-11\u0026#39; }, { title: \u0026#34;Chapter 7 - Inference for Numerical Data\u0026#34;, url: \u0026#34;/chapters/chapter7\u0026#34;, start: \u0026#39;2021-10-11\u0026#39;, end: \u0026#39;2021-10-18\u0026#39; }, { title: \u0026#34;Chapter 8 Linear Regression\u0026#34;, url: \u0026#34;/chapters/chapter8\u0026#34;, start: \u0026#39;2021-10-18\u0026#39;, end: \u0026#39;2021-11-01\u0026#39; }, { title: \u0026#34;Chapter 9 - Multiple \u0026amp; Logistic Regression\u0026#34;, url: \u0026#34;/chapters/chapter9\u0026#34;, start: \u0026#39;2021-11-01\u0026#39;, end: \u0026#39;2021-11-22\u0026#39; }, { title: \u0026#34;Thanksgiving Break\u0026#34;, start: \u0026#39;2021-11-22\u0026#39;, end: \u0026#39;2021-11-29\u0026#39; }, { title: \u0026#34;Intro to Bayesian Analysis\u0026#34;, url: \u0026#34;/chatpers/bayesian/\u0026#34;, start: \u0026#39;2021-11-29\u0026#39;, end: \u0026#39;2021-12-08\u0026#39; }, { title: \u0026#34;Final Exam\u0026#34;, url: \u0026#34;/assesssments/final/\u0026#34;, start: \u0026#39;2021-12-08\u0026#39;, end: \u0026#39;2021-12-13\u0026#39; }, { title: \u0026#39;Intro to the Course\u0026#39;, url: \u0026#34;/course-overview/meetups\u0026#34;, start: …","date":-62135596800,"description":"Schedule","objectID":"f7dc0ddb12acecfcbc25b8315ef44db3","permalink":"/course-overview/schedule/","title":"Schedule"},{"content":"R and RStudio We will make use of R, an open source statistics program and language. Be sure to install R and RStudio on your own computers within the first few days of the class.\n R - download for Windows, Mac, or Linux. RStudio - Download Windows, Mac, or Linux versions from here  If using Windows, you also need to download RTools and ActivePerl.\nLaTeX LaTeX is a typesetting language for preparing documents. Documents are written in plain text files. Formatting the document is done using specific markup. If you have used HTML, the framework is similar however instead of using \u0026amp;lt;TAG\u0026amp;gt;\u0026amp;lt;/TAG\u0026amp;gt; syntax, LaTeX uses \\TAG{} format. We will primarily use Markdown, and its extension R Markdown for preparing documents in this class. However, when preparing PDF documents, the Markdown will first be converted to LaTeX before creating the PDF file. As such, a LaTeX converter is necessary. There are LaTeX installers for Windows (MiKTeX) and Mac (BasicTeX). Alternatively, the tinytex R package provides an easier way of installing LaTeX directly from within R:\n Copy install.packages(\u0026amp;#39;tinytex\u0026amp;#39;) tinytex::install_tinytex()    Source Control All course materials will be made available on Github which provides an implementation of the git open source version control system. RStudio supports git directly, but I recommend downloading Sourcetree. This is a free desktop client that provides an easier interface for working with Github. You will also need to create an account on Github.\nFor more information, Jenny Bryan\u0026amp;rsquo;s Happy Git and Github for the useR is a free online book covering the important features of source control for R users.\nR Packages Once everything is installed, execute the following command in RStudio to install the packages we will use for this class (you can copy-and-paste):\n Copy install.packages(c(\u0026amp;#39;openintro\u0026amp;#39;,\u0026amp;#39;OIdata\u0026amp;#39;,\u0026amp;#39;devtools\u0026amp;#39;,\u0026amp;#39;tidyverse\u0026amp;#39;, \u0026amp;#39;ggplot2\u0026amp;#39;, …","date":-62135596800,"description":"","objectID":"98b20e0a769d52e45135f2acf70a2939","permalink":"/course-overview/software/","title":"Software"},{"content":"Required \nDiez, D.M., Barr, C.D., \u0026amp;amp; Çetinkaya-Rundel, M. (2019). OpenIntro Statistics (4th Ed).\n This is an open source textbook and can be downloaded in PDF format here, from the OpenIntro website, or a printed copy can be ordered from Amazon.\n  \nNavarro, D. (2018, version 0.6). Learning Statistics with R\n This is free textbook that supplements a lot of the material covered in Diez and Barr. We will use the chapter on Bayesian analysis. You can download a PDF version, Bookdown version, or visit the author\u0026amp;rsquo;s website at learningstatisticswithr.com.\n Recommended Wickham, H., \u0026amp;amp; Grolemund, G. (2016) R for Data Science. O\u0026amp;rsquo;Reilly.\n Most of this books is available freely online at r4ds.had.co.nz/ but can be purchased from Amazon.\n Wickham, H. Advanced R. Baca Raton, FL: Taylor \u0026amp;amp; Francis Group.\n Most of this book is available freely online at adv-r.had.co.nz but can be purchased from Amazon.\n Kruschke, J.K. (2014). Doing Bayesian Data Analysis, Second Edition: A Tutorial with R, JAGS, and Stan (2nd Ed). London: Academic Press.\n This book can be purchased from Amazon, but also check out the author\u0026amp;rsquo;s webiste (doingbayesiandataanalysis.blogspot.com/) for additional resources.\n ","date":-62135596800,"description":"","objectID":"c6f4b45f4d128398165c00a9b884a0f8","permalink":"/course-overview/textbooks/","title":"Textbooks"}]